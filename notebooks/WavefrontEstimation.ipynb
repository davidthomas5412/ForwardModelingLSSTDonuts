{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wavefront Estimation\n",
    "*David Thomas and Emily Li 2019/07/11*\n",
    "\n",
    "**Abstract:** We implement the full forward-model-powered wavefront estimation.\n",
    "\n",
    "**Table of Contents:**\n",
    "- [Starter Code](#Starter-Code)\n",
    "- [Research Questions](#Research-Questions)\n",
    "\n",
    "## Starter Code\n",
    "Our goal is to estimate the zernike coefficients of the wavefront, which characterize the state telescope, from donut images of stars. We develop a pipeline to realize this goal. Most of the components have been introduced through the previous notebooks. Now we must synthesize them. Here are the steps of the pipeline:\n",
    "- Create telescope (potentially with a perturbation).\n",
    "- Raytrace a donut (at the field center (0,0) for now).\n",
    "- Find the zernikes by optimizing the forward model.\n",
    "    - We use an off-the-shelf optimizer to minimize a cost function.\n",
    "    - The cost function is the difference between forward modelled donut and raytraced donut.\n",
    "- Evaluate the zernikes to get a wavefront image.\n",
    "- Use the opd to get the true wavefront image.\n",
    "- Examine the difference between the true and predicted wavefront.\n",
    "\n",
    "#### Basic Script\n",
    "The script below captures these steps and highlights the abstractions and functionality we will need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "telescope = loadTelescope()\n",
    "donut = raytraceDonut(telescope)\n",
    "\n",
    "predZ = findZernikes(donut)\n",
    "predW = zernikesToWavefront(zernikes)\n",
    "trueW = opd(telescope)\n",
    "\n",
    "err = np.abs(trueW - predW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! What do we need to build so that this code will actually work?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support Functions\n",
    "Let's start by importing the modules we will need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from scipy.interpolate import interp2d\n",
    "from scipy.signal import correlate\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import batoid\n",
    "import yaml\n",
    "from batoid.utils import fieldToDirCos\n",
    "import galsim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we copy over the functions we developed in previous notebooks. We will be able to use these without change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lsstPixels(lattice, pix=10e-6):\n",
    "    \"\"\"\n",
    "    Pixelizes the lattice so that pixels correspond to LSST pixels.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    lattice: batoid.Lattice\n",
    "        The psf lattice to pixelize.\n",
    "    pix: float\n",
    "        The size in meters of an LSST pixel.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    lattice: batoid.Lattice\n",
    "        The re-pixelized lattice.\n",
    "    \n",
    "    Note\n",
    "    ----\n",
    "    We assume lattice1 has cartesian grid vectors.\n",
    "    \"\"\"\n",
    "    nx, ny = lattice.array.shape\n",
    "    dx, dy = lattice.primitiveVectors[0,0], lattice.primitiveVectors[1,1]\n",
    "    z = lattice.array\n",
    "    if dx < 0:\n",
    "        z = z[::-1,:]\n",
    "        dx = np.abs(dx)\n",
    "    if dy < 0:\n",
    "        z = z[:,::-1]\n",
    "        dy = np.abs(dy)\n",
    "    x = np.arange(nx) * dx\n",
    "    y = np.arange(ny) * dy\n",
    "    \n",
    "    interp = interp2d(x, y, z)\n",
    "    xprime = np.arange(nx * dx // pix) * pix\n",
    "    yprime = np.arange(ny * dy // pix) * pix\n",
    "\n",
    "    arr = interp(xprime, yprime)\n",
    "    primitiveVectors = np.eye(2) * pix\n",
    "    return batoid.Lattice(arr, primitiveVectors)\n",
    "\n",
    "def compare(donutLattice, psfLattice):\n",
    "    \"\"\"\n",
    "    Re-pixelizes, normalizes, and centers lattices so that they can be compared on the same footing.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    donutLattice: batoid.Lattice\n",
    "        The donut lattice.\n",
    "    psfLattice: batoid.Lattice\n",
    "        The psf lattice.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray, numpy.ndarray\n",
    "        The psf and donut images.\n",
    "    \n",
    "    Notes\n",
    "    -----\n",
    "    Assume psf is larger.\n",
    "    \"\"\"\n",
    "    psfprime = lsstPixels(psfLattice)\n",
    "    \n",
    "    psf = psfprime.array\n",
    "    donut = donutLattice.array\n",
    "    \n",
    "    # first pad smaller array so that both are the same size\n",
    "    psf_nx = psf.shape[0]\n",
    "    donut_nx = donut.shape[0]\n",
    "    nx = max(psf_nx, donut_nx)\n",
    "    larger = np.zeros((nx,nx))\n",
    "    if psf_nx > donut_nx:\n",
    "        larger[:donut_nx,:donut_nx] = donut\n",
    "        donut = larger\n",
    "    else:\n",
    "        larger[:psf_nx,:psf_nx] = psf\n",
    "        psf = larger\n",
    "        \n",
    "    # smart way to center them\n",
    "    center = nx // 2\n",
    "    corr = correlate(psf, donut, mode='same')\n",
    "    idx = np.argmax(corr)\n",
    "    xmatch = (idx // nx)\n",
    "    ymatch = (idx % nx)\n",
    "    dx = center - xmatch\n",
    "    dy = center - ymatch\n",
    "    psf = np.roll(np.roll(psf, dx, axis=0), dy, axis=1)\n",
    "    \n",
    "    donut /= donut.sum()\n",
    "    psf /= psf.sum()\n",
    "    \n",
    "    return donut, psf\n",
    "\n",
    "def loadTelescope(offset=1.5e-3):\n",
    "    \"\"\"\n",
    "    Convenience function for loading a telescope.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    offset: float\n",
    "        The offset of the detector. Defaults to 1.5e-3 = 1.5mm.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    batoid.Optic\n",
    "        The loaded telescope.\n",
    "    \"\"\"\n",
    "    LSST_g_fn = os.path.join(batoid.datadir, \"LSST\", \"LSST_g.yaml\")\n",
    "    config = yaml.safe_load(open(LSST_g_fn))\n",
    "    telescope = batoid.parse.parse_optic(config['opticalSystem'])\n",
    "    telescope = telescope.withGloballyShiftedOptic('LSST.LSSTCamera.Detector', [0, 0, offset])\n",
    "    return telescope\n",
    "\n",
    "def opd(telescope, theta_x=0, theta_y=0, wavelength=500e-9, nx=256, projection='zemax', lattice=False):\n",
    "    \"\"\"\n",
    "    Computes the optical path difference, or wavefront, of a telescope.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    telescope: batoid.Optic\n",
    "        The telescope for which to compute wavefront.\n",
    "    theta_x, theta_y : float\n",
    "        Field of incoming rays (gnomonic projection). Default to 0.\n",
    "    wavelength: float\n",
    "        The Wavelength of light. Defaults to 500e-9 = 500nm.\n",
    "    nx: int\n",
    "        Number of grid points in each dimension. Defaults to 2048.\n",
    "    projection : {'postel', 'zemax', 'gnomonic', 'stereographic', 'lambert', 'orthographic'}\n",
    "        Projection used to convert field angle to direction cosines.\n",
    "    lattice : bool, optional\n",
    "        If true, then decenter the grid so it spans (-N/2, N/2+1), as appropriate\n",
    "        for Fourier transforms.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    batoid.Lattice\n",
    "        The wavefront, or optical path difference, of the telescope.\n",
    "    \"\"\"\n",
    "    flux = 1\n",
    "    dirCos = fieldToDirCos(theta_x, theta_y, projection=projection)\n",
    "    rays = batoid.rayGrid(\n",
    "        telescope.dist/dirCos[2], telescope.pupilSize,\n",
    "        dirCos[0], dirCos[1], -dirCos[2],\n",
    "        nx, wavelength, flux, telescope.inMedium, lattice=lattice)\n",
    "    \n",
    "    # chief ray index.  works if lattice=True and nx is even,\n",
    "    # or if lattice=False and nx is odd\n",
    "    cridx = (nx//2)*nx+nx//2\n",
    "    \n",
    "    telescope.traceInPlace(rays, outCoordSys=batoid.globalCoordSys)\n",
    "    spherePoint = rays[cridx].r\n",
    "    \n",
    "    # We want to place the vertex of the reference sphere one radius length away from the\n",
    "    # intersection point.  So transform our rays into that coordinate system.\n",
    "    radius = np.hypot(telescope.sphereRadius, np.hypot(spherePoint[0], spherePoint[1]))\n",
    "    transform = batoid.CoordTransform(\n",
    "            batoid.globalCoordSys, batoid.CoordSys(spherePoint+np.array([0,0,radius])))\n",
    "    transform.applyForwardInPlace(rays)\n",
    "\n",
    "    sphere = batoid.Sphere(-radius)\n",
    "    sphere.intersectInPlace(rays) \n",
    "    t0 = rays[cridx].t\n",
    "    arr = np.ma.masked_array(t0-rays.t, mask=rays.vignetted).reshape(nx, nx)\n",
    "\n",
    "    primitiveVectors = np.vstack([[telescope.pupilSize/nx, 0], [0, telescope.pupilSize/nx]])\n",
    "    return batoid.Lattice(arr, primitiveVectors)\n",
    "\n",
    "def raytraceDonut(telescope, nphot=int(1e6), theta_x=0, theta_y=0, wavelength=500e-9):\n",
    "    \"\"\"Simulate a donut image by raytracing photons through telescope.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    telescope: batoid.Optic\n",
    "        The telescope to raytrace through.\n",
    "    nphot: int\n",
    "        The number of photons to raytrace. Defaults to 1 million.\n",
    "    theta_x: float\n",
    "        The x field position. Defaults to 0.\n",
    "    theta_y: float\n",
    "        The y field position. Defaults to 0.\n",
    "    wavelength: float\n",
    "        The wavelength of light to use. Defaults to 500e-9 = 500 nm.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    batoid.Lattice\n",
    "        The donut image.\n",
    "    \"\"\"\n",
    "    flux = 1\n",
    "    xcos, ycos, zcos = batoid.utils.gnomonicToDirCos(theta_x, theta_y)\n",
    "    rays = batoid.uniformCircularGrid(\n",
    "        telescope.dist, \n",
    "        telescope.pupilSize/2, \n",
    "        telescope.pupilSize*telescope.pupilObscuration/2,\n",
    "        xcos, ycos, -zcos,\n",
    "        nphot, wavelength, flux,\n",
    "        telescope.inMedium)\n",
    "    telescope.traceInPlace(rays)\n",
    "    rays.trimVignettedInPlace()\n",
    "    \n",
    "    xcent, ycent = np.median(rays.x), np.median(rays.y)\n",
    "    pix = 10e-6\n",
    "    width = 192 * pix\n",
    "    \n",
    "    xedges = np.arange(xcent-width/2, xcent+width/2, pix)\n",
    "    yedges = np.arange(ycent-width/2, ycent+width/2, pix)\n",
    "    # flip here because 1st dimension corresponds to y-dimension in bitmap image\n",
    "    result, _, _ = np.histogram2d(rays.y, rays.x, bins=[yedges, xedges])\n",
    "    \n",
    "    primitiveX = np.array([[pix,0],[0,pix]])\n",
    "    return batoid.Lattice(result, primitiveX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "1.5mm / 10.31 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will need to write three new support functions. I have implemented the cost function for you. You will need to implement 'fftPSF'. This function will be almost identical to the function with the same name in the [ForwardModelingDonuts.ipynb](https://github.com/davidthomas5412/ForwardModelingLSSTDonuts/blob/master/notebooks/ForwardModelingDonuts.ipynb) notebook, but there are two differences described in the comments below. \n",
    "\n",
    "You will also need to fill in 'zernikesToWavefront'. This function takes a vector of zernike coefficients as input and produces the corresponding image. This will be similar to the work you did in [ZernikePolynomials.ipynb](https://github.com/davidthomas5412/ForwardModelingLSSTDonuts/blob/master/notebooks/ZernikePolynomials.ipynb). Remember to use the annular form of the zernike polynomials. Also to get the correct size of the image - number of pixels to use etc. - a number of geometric parameters are needed. Note that the size of a donut is (focalLength / diameter) * (absOffset / pixSize).\n",
    "\n",
    "**Problem 1:** Why does this give the diameter of a donut?\n",
    "\n",
    "**Problem 2:** Fill in the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cost(donut1, donut2):\n",
    "    \"\"\"\n",
    "    The L2 norm of the two donut images.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    donut1: numpy.ndarray\n",
    "        The image of donut 1.\n",
    "    donut2: numpy.ndarray\n",
    "        The image of donut 2.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The L2 difference.\n",
    "    \"\"\"\n",
    "    return np.sum((donut1 - donut2) ** 2)\n",
    "\n",
    "def fftPSF(zernikes, theta_x=0, theta_y=0, wavelength=500e-9, nx=2500, projection='zemax', pad_factor=1):\n",
    "    # TODO: your code here.\n",
    "    \n",
    "    # Note: This function will be a little different than the one in ForwardModelingDonuts.ipynb.\n",
    "    # First it will be a function of zernikes as opposed to the telescope. Then you can evaluate \n",
    "    # the zernikes to get the wavefront ('wf' in the other code) and use the nominal state of the telescope \n",
    "    # with batoid.psf.dkdu. \n",
    "    \n",
    "    \n",
    "def zernikesToWavefront(zernikes, absOffset=1.5e-3, pixSize=10e-6, focalLength=10.31, diameter=8.31):\n",
    "    \"\"\"\n",
    "    Produces the image of these zernikes.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    zernikes: numpy.ndarray\n",
    "        Vector of zernike coefficients.\n",
    "    absOffset: float\n",
    "        The absolute value of the offset from focus in meters. Defaults to 1.5e-3 = 1.5mm.\n",
    "    pixSize: float\n",
    "        The size of a LSST pixel in meters. Defaults to 10e-6 = 10um.\n",
    "    focalLength: float\n",
    "        The LSST focal length in meters. Defaults to 10.31m.\n",
    "    diameter: float\n",
    "        The outer diameter of the primary mirror M1 in meters. Defaults to 8.31m.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray\n",
    "        The corresponding image.\n",
    "    \"\"\"\n",
    "    # TODO: your code here\n",
    "    \n",
    "    # Note the diameter of a donut is (diameter / focalLength ) * (absOffset / pixSize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wavefront Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is how we put these pieces together to find the zernike coefficients from a raytraced donut image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "def findZernikes(raytracedDonut):\n",
    "    \"\"\"\n",
    "    Estimates the zernikes of the wavefront from a donut.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    raytracedDonut: numpy.ndarray\n",
    "        The donut image.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray\n",
    "        The vector of zernike coefficients.\n",
    "    \"\"\"\n",
    "    # function to optimize\n",
    "    def func(zernikes):\n",
    "        psfLattice = fftPSF(zernikes)\n",
    "        donut, estimate = compare(raytracedDonut, psfLattice)\n",
    "        return cost(donut, estimate)\n",
    "    \n",
    "    w0 = np.zeros(22)\n",
    "    res = minimize(w0, func)\n",
    "    \n",
    "    # raise Error if optimization fails\n",
    "    if not res.success:\n",
    "        print('Message: ', res.message)\n",
    "        print('Status: ', res.status)\n",
    "        raise RuntimeError('Optimizer Failed')\n",
    "        \n",
    "    zernikes = res.x\n",
    "    return zernikes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 3:** Write and debug code to get the 'basic script' to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "telescope = loadTelescope()\n",
    "donut = raytraceDonut(telescope)\n",
    "\n",
    "predZ = findZernikes(donut)\n",
    "predW = zernikesToWavefront(zernikes)\n",
    "trueW = opd(telescope)\n",
    "\n",
    "err = np.abs(trueW - predW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Questions\n",
    "Now that we have finished the pipeline we can embark on many research questions. These fall into a couple themes.\n",
    "- Runtime: What is the runtime of the different pieces of the pipeline? How can we make the optimization faster? Can we decrease the number of photons?\n",
    "- Accuracy: How accurate is the pipeline? Is it more accurate on certain perturbations? How does the number of photons used in the raytracing impact accuracy? What if we add poisson background noise to the donut image?\n",
    "- Optimization: What does the optimization surface look like? Which scipy minimizer is best? What are the trade-offs? Can we trade accuracy for better runtime?\n",
    "- Artifacts: How do fourier transform artifacts (the rings in the fftPSF) impact the pipeline? Can we remove them?\n",
    "- Visualization: How can we visualize the optimization surface? What diagnostic metrics can we use to assess the optimization (ex. hessian matrix)?\n",
    "- Generalization: How can we generalize this technique to other field positions? How does it compare to other approaches?\n",
    "\n",
    "We can start with the most immediate questions, and progress to more open ended questions. Congratulations on completing the basic training! Welcome to the journey that is research!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
